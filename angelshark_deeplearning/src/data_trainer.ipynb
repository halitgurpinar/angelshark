{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = os.getenv(\"HOME\")\n",
    "raw_data = pd.read_csv(home_dir + '/Desktop/DataPacket/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_input = []\n",
    "output = raw_data[\"steering_angle\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 240\n",
    "w = 320\n",
    "img_num = len(raw_data) + 1  # Because csv lenght start with 0\n",
    "\n",
    "for i in range(1, img_num):\n",
    "    img = cv2.imread(home_dir + \"/Desktop/DataPacket/Images/\"+str(i)+\".jpg\", 3)\n",
    "    img = cv2.resize(img, (w, h))\n",
    "    \n",
    "    img_input.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_input = np.asarray(img_input).astype(np.float32) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(img_input, output, test_size=0.2)\n",
    "\n",
    "del img_input\n",
    "del output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPool2D, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D, Cropping2D, Lambda\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 2, kernel_size = (3,3),padding = 'same',activation ='relu', input_shape = (h, w, 3)))\n",
    "model.add(Conv2D(filters = 4, kernel_size = (3,3),padding = 'same',activation ='relu'))\n",
    "model.add(Conv2D(filters = 8, kernel_size = (5,5),padding = 'same',activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(filters = 16, kernel_size = (5,5),padding = 'same',activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(filters = 24, kernel_size = (7,7),padding = 'same',activation ='relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(28, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs = model.fit(X_train, y_train, validation_data=(X_validation, y_validation), batch_size=64, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rospkg\n",
    "import rospy\n",
    "\n",
    "rospack = rospkg.RosPack()\n",
    "package_path = rospack.get_path('angelshark_deeplearning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pylab as plt\n",
    "import random\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# Save model weights and json.\n",
    "model.save_weights(package_path + '/model/model.h5')\n",
    "model_json = model.to_json()\n",
    "with open(package_path + '/model/model.json', 'w') as outfile:\n",
    "    json.dump(model_json, outfile)\n",
    "\n",
    "# Train and validation loss chart\n",
    "print(hs.history.keys())\n",
    "\n",
    "plt.plot(hs.history['loss'])\n",
    "plt.plot(hs.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
