{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = os.getenv(\"HOME\")\n",
    "raw_data = pd.read_csv(home_dir + '/Desktop/DataPacket/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>laser0</th>\n",
       "      <th>laser1</th>\n",
       "      <th>laser2</th>\n",
       "      <th>laser3</th>\n",
       "      <th>laser4</th>\n",
       "      <th>laser5</th>\n",
       "      <th>laser6</th>\n",
       "      <th>laser7</th>\n",
       "      <th>laser8</th>\n",
       "      <th>laser9</th>\n",
       "      <th>...</th>\n",
       "      <th>laser352</th>\n",
       "      <th>laser353</th>\n",
       "      <th>laser354</th>\n",
       "      <th>laser355</th>\n",
       "      <th>laser356</th>\n",
       "      <th>laser357</th>\n",
       "      <th>laser358</th>\n",
       "      <th>laser359</th>\n",
       "      <th>speed</th>\n",
       "      <th>steering_angle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.228333</td>\n",
       "      <td>0.227496</td>\n",
       "      <td>0.234184</td>\n",
       "      <td>0.253645</td>\n",
       "      <td>0.238905</td>\n",
       "      <td>0.224904</td>\n",
       "      <td>0.219742</td>\n",
       "      <td>0.225911</td>\n",
       "      <td>0.236172</td>\n",
       "      <td>0.221523</td>\n",
       "      <td>...</td>\n",
       "      <td>0.224054</td>\n",
       "      <td>0.248701</td>\n",
       "      <td>0.230076</td>\n",
       "      <td>0.243954</td>\n",
       "      <td>0.245454</td>\n",
       "      <td>0.225626</td>\n",
       "      <td>0.246615</td>\n",
       "      <td>0.244948</td>\n",
       "      <td>0.244948</td>\n",
       "      <td>0.585937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.228333</td>\n",
       "      <td>0.227496</td>\n",
       "      <td>0.234184</td>\n",
       "      <td>0.253645</td>\n",
       "      <td>0.238905</td>\n",
       "      <td>0.224904</td>\n",
       "      <td>0.219742</td>\n",
       "      <td>0.225911</td>\n",
       "      <td>0.236172</td>\n",
       "      <td>0.221523</td>\n",
       "      <td>...</td>\n",
       "      <td>0.224054</td>\n",
       "      <td>0.248701</td>\n",
       "      <td>0.230076</td>\n",
       "      <td>0.243954</td>\n",
       "      <td>0.245454</td>\n",
       "      <td>0.225626</td>\n",
       "      <td>0.246615</td>\n",
       "      <td>0.244948</td>\n",
       "      <td>0.244948</td>\n",
       "      <td>0.585937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.231983</td>\n",
       "      <td>0.244641</td>\n",
       "      <td>0.244981</td>\n",
       "      <td>0.224927</td>\n",
       "      <td>0.235483</td>\n",
       "      <td>0.222170</td>\n",
       "      <td>0.225249</td>\n",
       "      <td>0.235063</td>\n",
       "      <td>0.217606</td>\n",
       "      <td>0.233925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233786</td>\n",
       "      <td>0.242592</td>\n",
       "      <td>0.240255</td>\n",
       "      <td>0.225518</td>\n",
       "      <td>0.239098</td>\n",
       "      <td>0.246102</td>\n",
       "      <td>0.236991</td>\n",
       "      <td>0.250182</td>\n",
       "      <td>0.250182</td>\n",
       "      <td>0.600930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.237585</td>\n",
       "      <td>0.226259</td>\n",
       "      <td>0.225327</td>\n",
       "      <td>0.241955</td>\n",
       "      <td>0.234837</td>\n",
       "      <td>0.225581</td>\n",
       "      <td>0.239836</td>\n",
       "      <td>0.223831</td>\n",
       "      <td>0.220821</td>\n",
       "      <td>0.220462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239585</td>\n",
       "      <td>0.228006</td>\n",
       "      <td>0.226670</td>\n",
       "      <td>0.248297</td>\n",
       "      <td>0.234633</td>\n",
       "      <td>0.228943</td>\n",
       "      <td>0.237144</td>\n",
       "      <td>0.233428</td>\n",
       "      <td>0.233428</td>\n",
       "      <td>0.600727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.222417</td>\n",
       "      <td>0.230397</td>\n",
       "      <td>0.242593</td>\n",
       "      <td>0.251118</td>\n",
       "      <td>0.238735</td>\n",
       "      <td>0.237531</td>\n",
       "      <td>0.239533</td>\n",
       "      <td>0.239257</td>\n",
       "      <td>0.240184</td>\n",
       "      <td>0.254118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.244356</td>\n",
       "      <td>0.262002</td>\n",
       "      <td>0.238537</td>\n",
       "      <td>0.229623</td>\n",
       "      <td>0.220751</td>\n",
       "      <td>0.249123</td>\n",
       "      <td>0.232163</td>\n",
       "      <td>0.234454</td>\n",
       "      <td>0.234454</td>\n",
       "      <td>0.591369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 362 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     laser0    laser1    laser2    laser3    laser4    laser5    laser6  \\\n",
       "0  0.228333  0.227496  0.234184  0.253645  0.238905  0.224904  0.219742   \n",
       "1  0.228333  0.227496  0.234184  0.253645  0.238905  0.224904  0.219742   \n",
       "2  0.231983  0.244641  0.244981  0.224927  0.235483  0.222170  0.225249   \n",
       "3  0.237585  0.226259  0.225327  0.241955  0.234837  0.225581  0.239836   \n",
       "4  0.222417  0.230397  0.242593  0.251118  0.238735  0.237531  0.239533   \n",
       "\n",
       "     laser7    laser8    laser9  ...  laser352  laser353  laser354  laser355  \\\n",
       "0  0.225911  0.236172  0.221523  ...  0.224054  0.248701  0.230076  0.243954   \n",
       "1  0.225911  0.236172  0.221523  ...  0.224054  0.248701  0.230076  0.243954   \n",
       "2  0.235063  0.217606  0.233925  ...  0.233786  0.242592  0.240255  0.225518   \n",
       "3  0.223831  0.220821  0.220462  ...  0.239585  0.228006  0.226670  0.248297   \n",
       "4  0.239257  0.240184  0.254118  ...  0.244356  0.262002  0.238537  0.229623   \n",
       "\n",
       "   laser356  laser357  laser358  laser359     speed  steering_angle  \n",
       "0  0.245454  0.225626  0.246615  0.244948  0.244948        0.585937  \n",
       "1  0.245454  0.225626  0.246615  0.244948  0.244948        0.585937  \n",
       "2  0.239098  0.246102  0.236991  0.250182  0.250182        0.600930  \n",
       "3  0.234633  0.228943  0.237144  0.233428  0.233428        0.600727  \n",
       "4  0.220751  0.249123  0.232163  0.234454  0.234454        0.591369  \n",
       "\n",
       "[5 rows x 362 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPool2D, Dropout, Concatenate, Input\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_start = 0\n",
    "data_stop = 1000\n",
    "data_part = raw_data[data_start:data_stop]\n",
    "speed = data_part[\"speed\"].values\n",
    "steering_angle = data_part[\"steering_angle\"].values\n",
    "output = np.dstack((steering_angle, speed))[0]\n",
    "\n",
    "img_input = []\n",
    "h = 240\n",
    "w = 320\n",
    "c = 3\n",
    "for i in range(data_start+1, data_stop+1):\n",
    "    img = cv2.imread(home_dir + \"/Desktop/DataPacket/Images/\"+str(i)+\".jpg\", c)\n",
    "    img = cv2.resize(img, (w, h))\n",
    "    img_input.append(img)\n",
    "img_input = np.asarray(img_input).astype(np.float32) / 255.0\n",
    "print(\"img input shape:\",img_input.shape)\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(img_input, output, test_size=0.2, random_state=22)\n",
    "if len(X_train.shape) < 4:  # We do this because when image is grey cv2 not add channel num to shape but keras want to see 1 as channel\n",
    "    X_train.resize(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "    X_validation.resize(X_validation.shape[0], X_validation.shape[1], X_validation.shape[2], 1)\n",
    "del img_input\n",
    "del steering_angle\n",
    "del output\n",
    "del speed\n",
    "print(\"1st part x train shape:\",X_train.shape)\n",
    "print(\"1st part y train shape:\",y_train.shape)\n",
    "print(\"1st part laser data shape:\",laser_data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "dataGenerator = ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False,\n",
    "        rotation_range=5,\n",
    "        zoom_range = 0.1, \n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1, \n",
    "        horizontal_flip=False,\n",
    "        vertical_flip=False)\n",
    "dataGenerator.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 2, kernel_size = (3,3),padding = 'same',activation ='relu', input_shape = (h, w, c)))\n",
    "model.add(Conv2D(filters = 4, kernel_size = (3,3),padding = 'same',activation ='relu'))\n",
    "model.add(Conv2D(filters = 8, kernel_size = (5,5),padding = 'same',activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(filters = 16, kernel_size = (5,5),padding = 'same',activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(filters = 24, kernel_size = (7,7),padding = 'same',activation ='relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "'''model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(28, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))'''\n",
    "\n",
    "model.add(Dense(2, activation = \"softmax\"))\n",
    "\n",
    "model.compile(loss='mse', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs = model.fit(X_train, y_train, validation_data=(X_validation, y_validation), batch_size=64, epochs=3)\n",
    "#hs = model.fit_generator(dataGenerator.flow(X_train, y_train, batch_size=64), epochs=3, validation_data=[X_validation, y_validation], steps_per_epoch=X_train.shape[0] // 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_start = 1000\n",
    "data_stop = 2000\n",
    "for part in range(1,int(len(raw_data)/1000)+1):\n",
    "    if data_stop > len(raw_data):\n",
    "        data_stop = len(raw_data)\n",
    "    if data_stop <= data_start:\n",
    "        break\n",
    "    data_part = raw_data[data_start:data_stop]\n",
    "    speed = data_part[\"speed\"].values\n",
    "    steering_angle = data_part[\"steering_angle\"].values\n",
    "    output = np.dstack((steering_angle, speed))[0]\n",
    "    \n",
    "    img_input = []\n",
    "    h = 240\n",
    "    w = 320\n",
    "    c = 3\n",
    "    for i in range(data_start+1, data_stop+1):\n",
    "        img = cv2.imread(home_dir + \"/Desktop/DataPacket/Images/\"+str(i)+\".jpg\", c)\n",
    "        img = cv2.resize(img, (w, h))\n",
    "        img_input.append(img)\n",
    "    img_input = np.asarray(img_input).astype(np.float32) / 255.0\n",
    "    print(\"img input shape:\",img_input.shape)\n",
    "    \n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(img_input, output, test_size=0.2, random_state=22)\n",
    "    dataGenerator = ImageDataGenerator(\n",
    "            featurewise_center=False,\n",
    "            samplewise_center=False,\n",
    "            featurewise_std_normalization=False,\n",
    "            samplewise_std_normalization=False,\n",
    "            zca_whitening=False,\n",
    "            rotation_range=5,\n",
    "            zoom_range = 0.1, \n",
    "            width_shift_range=0.1,\n",
    "            height_shift_range=0.1, \n",
    "            horizontal_flip=False,\n",
    "            vertical_flip=False)\n",
    "    dataGenerator.fit(X_train)\n",
    "    del img_input\n",
    "    del steering_angle\n",
    "    del output\n",
    "    del speed\n",
    "    print(part+1,\"th part x train shape:\",X_train.shape)\n",
    "    print(part+1,\"th part y train shape:\",y_train.shape)\n",
    "    print(part+1,\"th part laser data shape:\",laser_data.shape[1])\n",
    "    hs = model.fit(X_train, y_train, validation_data=(X_validation, y_validation), batch_size=64, epochs=3)\n",
    "    #hs = model.fit_generator(dataGenerator.flow(X_train, y_train, batch_size=64), epochs=3, validation_data=[X_validation, y_validation], steps_per_epoch=X_train.shape[0] // 64)\n",
    "    data_start = data_start + 1000\n",
    "    data_stop = data_stop + 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "from plotly.offline import iplot\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "def trainingResultsGraph(model, modelCode):\n",
    "    trace0 = go.Scatter(\n",
    "        x = model.epoch,\n",
    "        y = model.history['loss'],\n",
    "        mode = 'lines',\n",
    "        name = 'loss',\n",
    "        line=dict(color='aquamarine')\n",
    "    )\n",
    "\n",
    "    trace1 = go.Scatter(\n",
    "        x = model.epoch,\n",
    "        y = model.history['val_loss'],\n",
    "        mode = 'lines',\n",
    "        name = 'val_loss',\n",
    "        line=dict(color='darkred', dash='dash')\n",
    "    )\n",
    "\n",
    "    trace2 = go.Scatter(\n",
    "        x = model.epoch,\n",
    "        y = model.history['acc'],\n",
    "        mode = 'lines',\n",
    "        name = 'acc',\n",
    "        line=dict(color='violet')\n",
    "    )\n",
    "\n",
    "    trace3 = go.Scatter(\n",
    "        x = model.epoch,\n",
    "        y = model.history['val_acc'],\n",
    "        mode = 'lines',\n",
    "        name = 'val_acc',\n",
    "        line=dict(color='aqua', dash='dash')\n",
    "    )\n",
    "\n",
    "    updatemenus = list([\n",
    "        dict(type=\"buttons\",\n",
    "             active=-1,\n",
    "             buttons=list([\n",
    "                dict(label = 'Acc Graph',\n",
    "                     method = 'update',\n",
    "                     args = [{'visible': [False, False, True, True]},\n",
    "                             {'title': 'Trained Model'+modelCode+' training and validation accuracy'}]),\n",
    "                dict(label = 'Loss Graph',\n",
    "                     method = 'update',\n",
    "                     args = [{'visible': [True, True, False, False]},\n",
    "                             {'title': 'Trained Model'+modelCode+' training and validation loss'}]),\n",
    "                dict(label = 'Both',\n",
    "                     method = 'update',\n",
    "                     args = [{'visible': [True, True, True, True]},\n",
    "                             {'title': 'Trained Model'+modelCode+' training and validation values'}])\n",
    "            ]),\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    data = [trace0, trace1, trace2, trace3]\n",
    "    layout = dict(title='Trained Model'+modelCode+' training and validation values',\n",
    "                  xaxis = dict(title = 'Epochs'),\n",
    "                  updatemenus=updatemenus)\n",
    "\n",
    "    fig = dict(data=data, layout=layout)\n",
    "\n",
    "    iplot(fig, filename='lossGraph')\n",
    "    \n",
    "trainingResultsGraph(hs, \"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import rospkg\n",
    "    import rospy\n",
    "\n",
    "    rospack = rospkg.RosPack()\n",
    "    package_path = rospack.get_path('angelshark_deeplearning')\n",
    "    \n",
    "except ImportError:\n",
    "    package_path = home_dir + \"/Desktop\"\n",
    "    \n",
    "    import os\n",
    "    if not os.path.exists(package_path + \"/model\"):\n",
    "        os.makedirs(package_path + \"/model\")\n",
    "    \n",
    "    print(\"Please move them to deeplearning package model directory to angelshark_deeplearning/model\")\n",
    "    \n",
    "print(\"Model saved to \",str(package_path),\" dir!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pylab as plt\n",
    "import random\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# Save model weights and json.\n",
    "model.save_weights(package_path + '/model/model.h5')\n",
    "model_json = model.to_json()\n",
    "with open(package_path + '/model/model.json', 'w') as outfile:\n",
    "    json.dump(model_json, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and validation loss chart\n",
    "print(hs.history.keys())\n",
    "\n",
    "plt.plot(hs.history['loss'])\n",
    "plt.plot(hs.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
