{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = os.getenv(\"HOME\")\n",
    "raw_data = pd.read_csv(home_dir + '/Desktop/DataPacket/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPool2D, Dropout, Concatenate, Input\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_start = 0\n",
    "data_stop = 1000\n",
    "data_part = raw_data[data_start:data_stop]\n",
    "laser_data = data_part.drop([\"steering_angle\", \"speed\"], axis=1)\n",
    "laser_data = laser_data.values\n",
    "maximum_laser_range = 12.0\n",
    "for i in range(len(laser_data)):\n",
    "    for j in range(len(laser_data[i])):\n",
    "        if np.isinf(laser_data[i][j]):\n",
    "            laser_data[i][j] = maximum_laser_range\n",
    "laser_data = laser_data / 12\n",
    "X_laser_train, X_laser_validation = train_test_split(laser_data, test_size=0.2)\n",
    "speed = data_part[\"speed\"].values\n",
    "steering_angle = data_part[\"steering_angle\"].values\n",
    "output = np.dstack((steering_angle, speed))[0]\n",
    "\n",
    "img_input = []\n",
    "h = 240\n",
    "w = 320\n",
    "c = 3\n",
    "for i in range(data_start+1, data_stop+1):\n",
    "    img = cv2.imread(home_dir + \"/Desktop/DataPacket/Images/\"+str(i)+\".jpg\", c)\n",
    "    img = cv2.resize(img, (w, h))\n",
    "    img_input.append(img)\n",
    "img_input = np.asarray(img_input).astype(np.float32) / 255.0\n",
    "print(\"img input shape:\",img_input.shape)\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(img_input, output, test_size=0.2, random_state=22)\n",
    "del img_input\n",
    "del steering_angle\n",
    "del output\n",
    "del speed\n",
    "print(\"1st part x train shape:\",X_train.shape)\n",
    "print(\"1st part y train shape:\",y_train.shape)\n",
    "print(\"1st part laser data shape:\",laser_data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 2, kernel_size = (3,3),padding = 'same',activation ='relu'))\n",
    "model.add(Conv2D(filters = 4, kernel_size = (3,3),padding = 'same',activation ='relu'))\n",
    "model.add(Conv2D(filters = 8, kernel_size = (5,5),padding = 'same',activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(filters = 16, kernel_size = (5,5),padding = 'same',activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(filters = 24, kernel_size = (7,7),padding = 'same',activation ='relu'))\n",
    "model.add(Flatten())\n",
    "\n",
    "image_input = Input(shape=(h, w, c))\n",
    "flatten_image_outputs = model(image_input)\n",
    "\n",
    "laser_input = Input(shape = (laser_data.shape[1],))\n",
    "concatenatedFeatures = Concatenate(axis = 1)([laser_input, flatten_image_outputs])\n",
    "\n",
    "dense = Dense(128, activation = \"relu\")(concatenatedFeatures)\n",
    "dense = Dense(64, activation = \"relu\")(dense)\n",
    "dense = Dense(16, activation = \"relu\")(dense)\n",
    "main_output = Dense(2, activation = \"softmax\")(dense)\n",
    "\n",
    "drive_model = Model(inputs=[image_input,laser_input], outputs=main_output)\n",
    "\n",
    "drive_model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs = drive_model.fit([X_train, X_laser_train], y_train, validation_data=([X_validation, X_laser_validation], y_validation), batch_size=64, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_start = 1000\n",
    "data_stop = 2000\n",
    "for part in range(1,int(len(raw_data)/1000)+1):\n",
    "    if data_stop > len(raw_data):\n",
    "        data_stop = len(raw_data)\n",
    "    if data_stop <= data_start:\n",
    "        break\n",
    "    data_part = raw_data[data_start:data_stop]\n",
    "    laser_data = data_part.drop([\"steering_angle\", \"speed\"], axis=1)\n",
    "    laser_data = laser_data.values\n",
    "    maximum_laser_range = 12.0\n",
    "    for i in range(len(laser_data)):\n",
    "        for j in range(len(laser_data[i])):\n",
    "            if np.isinf(laser_data[i][j]):\n",
    "                laser_data[i][j] = maximum_laser_range\n",
    "    laser_data = laser_data / 12\n",
    "    X_laser_train, X_laser_validation = train_test_split(laser_data, test_size=0.2)\n",
    "    speed = data_part[\"speed\"].values\n",
    "    steering_angle = data_part[\"steering_angle\"].values\n",
    "    output = np.dstack((steering_angle, speed))[0]\n",
    "    \n",
    "    img_input = []\n",
    "    h = 240\n",
    "    w = 320\n",
    "    c = 3\n",
    "    for i in range(data_start+1, data_stop+1):\n",
    "        img = cv2.imread(home_dir + \"/Desktop/DataPacket/Images/\"+str(i)+\".jpg\", c)\n",
    "        img = cv2.resize(img, (w, h))\n",
    "        img_input.append(img)\n",
    "    img_input = np.asarray(img_input).astype(np.float32) / 255.0\n",
    "    print(\"img input shape:\",img_input.shape)\n",
    "    \n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(img_input, output, test_size=0.2, random_state=22)\n",
    "    del img_input\n",
    "    del steering_angle\n",
    "    del output\n",
    "    del speed\n",
    "    print(part+1,\"th part x train shape:\",X_train.shape)\n",
    "    print(part+1,\"th part y train shape:\",y_train.shape)\n",
    "    print(part+1,\"th part laser data shape:\",laser_data.shape[1])\n",
    "    hs = drive_model.fit([X_train, X_laser_train], y_train, validation_data=([X_validation, X_laser_validation], y_validation), batch_size=64, epochs=5)\n",
    "    data_start = data_start + 1000\n",
    "    data_stop = data_stop + 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "from plotly.offline import iplot\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "def trainingResultsGraph(model, modelCode):\n",
    "    trace0 = go.Scatter(\n",
    "        x = drive_model.epoch,\n",
    "        y = drive_model.history['loss'],\n",
    "        mode = 'lines',\n",
    "        name = 'loss',\n",
    "        line=dict(color='aquamarine')\n",
    "    )\n",
    "\n",
    "    trace1 = go.Scatter(\n",
    "        x = drive_model.epoch,\n",
    "        y = drive_model.history['val_loss'],\n",
    "        mode = 'lines',\n",
    "        name = 'val_loss',\n",
    "        line=dict(color='darkred', dash='dash')\n",
    "    )\n",
    "\n",
    "    trace2 = go.Scatter(\n",
    "        x = drive_model.epoch,\n",
    "        y = drive_model.history['acc'],\n",
    "        mode = 'lines',\n",
    "        name = 'acc',\n",
    "        line=dict(color='violet')\n",
    "    )\n",
    "\n",
    "    trace3 = go.Scatter(\n",
    "        x = drive_model.epoch,\n",
    "        y = drive_model.history['val_acc'],\n",
    "        mode = 'lines',\n",
    "        name = 'val_acc',\n",
    "        line=dict(color='aqua', dash='dash')\n",
    "    )\n",
    "\n",
    "    updatemenus = list([\n",
    "        dict(type=\"buttons\",\n",
    "             active=-1,\n",
    "             buttons=list([\n",
    "                dict(label = 'Acc Graph',\n",
    "                     method = 'update',\n",
    "                     args = [{'visible': [False, False, True, True]},\n",
    "                             {'title': 'Trained Model'+modelCode+' training and validation accuracy'}]),\n",
    "                dict(label = 'Loss Graph',\n",
    "                     method = 'update',\n",
    "                     args = [{'visible': [True, True, False, False]},\n",
    "                             {'title': 'Trained Model'+modelCode+' training and validation loss'}]),\n",
    "                dict(label = 'Both',\n",
    "                     method = 'update',\n",
    "                     args = [{'visible': [True, True, True, True]},\n",
    "                             {'title': 'Trained Model'+modelCode+' training and validation values'}])\n",
    "            ]),\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    data = [trace0, trace1, trace2, trace3]\n",
    "    layout = dict(title='Trained Model'+modelCode+' training and validation values',\n",
    "                  xaxis = dict(title = 'Epochs'),\n",
    "                  updatemenus=updatemenus)\n",
    "\n",
    "    fig = dict(data=data, layout=layout)\n",
    "\n",
    "    iplot(fig, filename='lossGraph')\n",
    "    \n",
    "trainingResultsGraph(hs, \"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import rospkg\n",
    "    import rospy\n",
    "\n",
    "    rospack = rospkg.RosPack()\n",
    "    package_path = rospack.get_path('angelshark_deeplearning')\n",
    "    \n",
    "except ImportError:\n",
    "    package_path = home_dir + \"/Desktop\"\n",
    "    \n",
    "    import os\n",
    "    if not os.path.exists(package_path + \"/model\"):\n",
    "        os.makedirs(package_path + \"/model\")\n",
    "    \n",
    "    print(\"Please move them to deeplearning package model directory to angelshark_deeplearning/model\")\n",
    "    \n",
    "print(\"Model saved to \",str(package_path),\" dir!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pylab as plt\n",
    "import random\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# Save model weights and json.\n",
    "drive_model.save_weights(package_path + '/model/model.h5')\n",
    "model_json = drive_model.to_json()\n",
    "with open(package_path + '/model/model.json', 'w') as outfile:\n",
    "    json.dump(model_json, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and validation loss chart\n",
    "print(hs.history.keys())\n",
    "\n",
    "plt.plot(hs.history['loss'])\n",
    "plt.plot(hs.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
